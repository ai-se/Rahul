from __future__ import division, print_functionimport sys, random; import pdbsys.dont_write_bytecode = Truedef settings(**d): return o(  name="DEADANT v0.1",  what="A stochastic multi-objective tabu active learner",  synopsis="""    DeadAnt's tabu memory is a trail of 'dead ants' in    regions known to be sub-optimal. Landing too close    to a dead ant will 'kill' any new candidate.  To    reduce the overhead of searching through the ants,    pairs of close dead ants are incrementally fused    together.  To better explore good solutions, if a    candidate is dominated by a live ant, then the    candidate is nudged towards the better ant. This is    an active learner since new solutions are only    evaluated if are not 'close' to a dead ant (where    'close' is learned dynamically).""",  _logo="""             "=.             "=. \                 \ \              _,-=\/=._        _.-,_            /         \      /=-._ "-.           |=-./~\___/~\    / How `-._\            |   \o/   \o/   /  to      /            \_   `~~~;/    |  Dodge   |              `~,._,-'    /   Dead   /                 | |      =-._Things/             _,-=/ \=-._     /|`-._/           //           \\   )\           /|    I See   |)_.'/         //|    Dead    |\_."   _.-\         (|  \   People /    _.`=    \         ||   ":_    _.;"_.-;"   _.-=.:     _-."/    / `-."\_."        =-_.;\     `-_./   /             _.-=.    / \\            |              =-_.;\ ."   \\            \                   \\/     \\            /\_                .'\\      \\           //  `=_         _.-"   \\      \\          //      `~-.=`"`'       ||      ||   LGB   ||    _.-_/|            ||      |\_.-_     _.-_/|   /_.-._/            |\_.-_  \_.-._\     /_.-._/                      \_.-._\     """,  author="Tim Menzies, Rahul Krishna",  copyleft="(c) 2014, MIT license, http://goo.gl/3UYBp",  seed=1,  np=10,  k=100,  kMore=1.1,  tiny=0.05,  start='print(The._logo)',  closeEnough=2,  de=o(np=5,       epsilon=1.01,       f=0.3,       cf=0.4,       lives=100)  ).update(**d)class o:  def __init__(self, **d): self.update(**d)  def update(self, **d): self.__dict__.update(**d); return selfrand = random.randomseed = random.seedany = random.choicedef say(*lst):  sys.stdout.write(' '.join(map(str, lst)))  sys.stdout.flush()def sayln(*lst):  say(*lst); print("")def _say(): sayln(1, 2, 3, 4)The = settings()def cmd(com=The.start):  if globals()["__name__"] == "__main__":    if len(sys.argv) == 3:      if sys.argv[1] == '--cmd':        com = sys.argv[2] + '()'    if len(sys.argv) == 4:        com = sys.argv[2] + '(' + sys.argv[3] + ')'    eval(com)class Close():  def __init__(self):    self.sum, self.n = [0] * 32, [0] * 32  def p(self, x):    for j in xrange(len(self.sum)):      mu = self.sum[j] / self.n[j] if self.n[j] else 0      if x > mu:        return self.n[j] / self.n[0]    return self.n[-1] / self.n[0]  def __iadd__(self, x):    for j in xrange(len(self.sum)):      self.sum[j] += x      self.n[j] += 1      mu = self.sum[j] / self.n[j]      if x >= mu: return self      if self.sum[j] < The.closeEnough: return self    return self  def close(self, x):    return self.p(x) < The.tinydef _close(n=10000, p=2, rseed=None):  seed(rseed or The.seed)  cl = Close()  for _ in xrange(n):    cl += rand() * 100  print(':p', cl.p(p), ':close', cl.close(p))  print(map(lambda x: int(x[0] / x[1]) if x[1] else 0, zip(cl.sum, cl.n)))class Col:  def any(self): return None  def fuse(self, x, w1, y, w2): return None  def nudge(self, x, y): return None  def dist(self, x, y): return 0  def norm(self, x) : return x  def extrapolate(self, x, y, z): return Noneclass N(Col):  "For nums"  def __init__(self, col=0, least=0, most=1, name=None):    self.col = col    self.name = None    self.least, self.most = least, most      self.lo, self.hi = 10 ** 32, -1 * 10 ** 32  def extrapolate(self, x, y, z):    f = The.de.f    return x + f * (y - z) if rand() < The.de.cf else x      def any(self):    return max(self.least,               min(self.most,                   self.least + rand() * (self.most - self.least)))  def __iadd__(self, x):    # print("x",x,"least",self.least,"most",self.most)    assert x >= self.least and x <= self.most    self.lo = min(self.lo, x)    self.hi = max(self.hi, x)    return self  def norm(self, x):    tmp = (x - self.lo) / (self.hi - self.lo + 0.00001)    return max(0, min(1, tmp))  def dist(self, x, y):    return self.norm(x) - self.norm(y)  def fuse(self, x, w1, y, w2):    return (x * w1 + y * w2) / (w1 + w2)  def nudge(self, x, y):    tmp = x + rand() * 1.5 * (y - x)    if tmp > self.most : tmp = self.least    if tmp < self.least: tmp = self.most    return tmp    class S(Col):  "For syms"  def __init__(self, col=0, items=[], name=None):    self.index = frozenset(items)    self.items = items    self.col = col    self.name = name   def any(self):    return random.choice(self.items)  def __iadd__(self, x):     assert x in self.index  def dist(self, x, y): return 0 if x == y else 0  def fuse(self, x, w1, y, w2):    return x if rand() <= w1 / (w1 + w2) else y  def nudge(self, x, y):    return x if rand() < 0.33 else y  def extrapolate(self, x, y, z):    if rand() >= The.de.cf:       return x    else:      w = y if rand() <= f else z       return x if rand() <= 0.5 else wclass O(Col):  "for objectives"  def __init__(self, col=0, f=lambda x: 1, name=None,    love=False  # for objectives to maximize, set love to True    ):    self.f = f    self.love = love    self.name = name or f.__name__    self.n = N(col=col, least=-10 ** 32, most=10 ** 32)  def score(self, lst):    x = lst[self.col]    if x == None:        x = self.f(lst)        self.n += x        lst[self.col] = x    return x  def better(self, x, y):    e = The.de.epsilon    return x > y * e if self.love else x < y / e  def worse(self, x, y):    return x < y if self.love else x > y  class Meta(Col):  id = 0  def __init__(self, of, weight=1, dead=True):    self.weight, self.dead, self.of = weight, dead, of    self.id = Meta.id = Meta.id + 1  def any(self):    return Meta(self.of)  def fuse(self, x, w1, y, w2):     tmp = self.any()    tmp.weight = w1 + w2    return tmp  def nudge(self, x, y): return self.any()  def __repr__(self):    return self.of.name + ':' \           + ('DEAD' if self.dead else 'ALIVE') \           + '*' + str(self.weight)def Schaffer():  def f1(row): return row[1] ** 2  def f2(row): return (row[1] - 2) ** 2  return Cols(Schaffer,                 [N(least=-4, most=4)                 , O(f=f1)                 , O(f=f2)                 ])def _schaffer():  m = Schaffer()  for _ in range(10):    one = m.any()    m.score(one)    print(one)  class Cols:  def __init__(self, factory, cols=[]):    self.cols = [Meta(self)] + cols    self.factory, self.name = factory, factory.__name__    self.nums = [];  self.syms = []; self.objs = []    for pos, header in enumerate(self.cols):      header.col = pos       if isinstance(header, N): self.nums += [header]      if isinstance(header, S): self.syms += [header]      if isinstance(header, O): self.objs += [header]    self.indep = self.nums + self.syms    self.cl = Close()  def any(self): return [z.any() for z in self.cols]  def tell(self, lst):     for z in self.indep: z += lst[z.col]  def score(self, l): return [z.score(l) for z in self.objs]  def nudge(self, lst1, lst2):    return [one.nudge(x, y)             for x, y, one in vals(lst1, lst2, self.cols)]  def extrapolate(self, lst1, lst2, lst3):    tmp = [one.extrapolate(x, y, z) for x, y, z, one in             vals3(lst1, lst2, lst3, self.cols)]    one = any(self.objs)    tmp[one.col] = lst1[one.col]    return tmp  def fuse(self, lst1, lst2):    w1 = lst1[0].weight    w2 = lst2[0].weight    return [one.fuse(x, w1, y, w2)             for x, y, one in vals(lst1, lst2, self.cols)]  def fromHell(self, lst):    x, c = 0, len(self.objs)    for header in self.objs:      val = header.col      tmp = header.norm(val)      tmp = tmp if header.love else 1 - tmp      x += tmp ** 2    return x ** 0.5 / c ** 0.5  def dominates(self, lst1, lst2):    self.score(lst1)    self.score(lst2)    better = False    for x, y, obj in vals(lst1, lst2, self.objs):      if obj.worse(x, y) : return False      if obj.better(x, y): better = True    return better  def dist(self, lst1, lst2, peeking=False):    total, c = 0, len(self.indep)    for x, y, indep in vals(lst1, lst2, self.indep):      total += indep.dist(x, y) ** 2     d = total ** 0.5 / c ** 0.5    if not peeking: self.cl += d    # Peeking? What's peeking?          return ddef vals(lst1, lst2, cols):  for c in cols:    yield lst1[c.col], lst2[c.col], cdef vals3(lst1, lst2, lst3, cols):  for c in cols:    yield lst1[c.col], lst2[c.col], lst3[c.col], cdef fromLine(a, b, c):    x = (a ** 2 + c ** 2 - b ** 2) / (2 * c)    return max(0, (a ** 2 - x ** 2)) ** 0.5def neighbors(m, lst1, pop):  return sorted([(m.dist(lst1, lst2), lst2)                  for lst2 in pop                  if not lst1[0].id == lst2[0].id])class deadAnt(object):  def __init__(self, model=Schaffer):    self.m=model()    self.pop = {}  def remember(self, new): self.pop[ new[ 0 ].id ] = new; self.m.tell(new)  def itsAlive(self, lst): lst[0].dead = False; return lst  def itsDead(self, lst) : lst[0].dead = True;  return lst  def itsGone(self, lst) : del self.pop[lst[0].id]  def makeSomeAnts(self, n) :    for _ in range(n):      self.remember(self.itsAlive(self.m.any()))  def DA(self):    self.makeSomeAnts(The.np * len(self.m.indep))  # initialize some ants    k = The.k  # k=100, see line 54    new = self.m.any()    while k > 0:      k -= 1      #pdb.set_trace()      (a, old), (b, other) = neighbors(self.m, new, self.pop.values())[:2]      #pdb.set_trace()            if not self.m.cl.close(a):        c = self.m.dist(old, other, peeking=True)        y = fromLine(a, b, c)        if not self.m.cl.close(y):          remember(self.itsAlive(new))          new = self.m.any()          continue        # else close enough to reflect on old      if old[0].dead:        new = self.m.fuse(new, old)        self.itsGone(old)        self.remember(self.itsDead(new))        new = self.m.any()      elif  self.m.dominates(new, old):        k *= The.kMore        self.itsDead(old)        self.remember(self.itsAlive(new))        new = self.m.nudge(old, new)      elif self.m.dominates(old, new):        self.remember(self.itsDead(new))        new = self.m.nudge(new, old)      else:        self.remember(self.itsAlive(new))        new = self.m.any()      return self.pop     def _deadAnt():  da=deadAnt();  res=da.DA()  print(res)  def one234(one, pop, f=lambda x:id(x)):   def oneOther():    x = any(pop)    while f(x) in seen:       x = any(pop)    seen.append(f(x))    return x  seen = [ f(one) ]  return oneOther(), oneOther(), oneOther()def _one234():  seed(The.seed)  for _ in range(10):    print(one234(1, range(1000)))def de(model=Schaffer):  seed(The.seed)  m = model()  frontier = []  def remember(new):     m.tell(new); frontier.append(new)  def pop0(n) :    for i in range(n):       remember(m.any())  pop0(The.np * len(m.indep))  lives = The.de.lives  while lives > 0:    say(lives)    better = False    for pos, l1 in enumerate(frontier):      lives -= 1      l2, l3, l4 = one234(l1, frontier)      candidate = m.extrapolate(l2, l3, l4)      if m.dominates(candidate, l1):        print(">>", m.fromHell(candidate) - m.fromHell(l1))        better = True        frontier[pos] = candidate      elif m.dominates(l1, candidate):        say("_")      else:        say(".")        remember(candidate)    # if better:     #  lives += 1cmd('_deadAnt()')